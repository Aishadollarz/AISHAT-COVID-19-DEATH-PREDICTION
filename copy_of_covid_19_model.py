# -*- coding: utf-8 -*-
"""Copy of COVID 19 MODEL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WIqvdQw-zOCQPz1wNQ0pw_X1EOprIIEl
"""

# Load the uploaded dataset to inspect its structure and content.
import pandas as pd

# File path of the uploaded dataset
file_path = '/content/covid 19 dataset.csv'

# Load the dataset
covid_data = pd.read_csv(file_path)

# Display basic information and the first few rows to understand the structure
covid_data_info = covid_data.info()
covid_data_head = covid_data.head()

covid_data_info, covid_data_head

# Check for duplicates
duplicates = covid_data.duplicated().sum()
print(f"Number of duplicates: {duplicates}")

# Remove duplicates if any
covid_data = covid_data.drop_duplicates()

# Check for missing values
missing_values = covid_data.isnull().sum()
print("Missing values per column:\n", missing_values)

# Standardize column names (optional: replacing spaces with underscores for easier handling)
covid_data.columns = covid_data.columns.str.strip().str.lower().str.replace(' ', '_')

# Display the cleaned data
covid_data.head()

# Example: Calculate daily growth rate (new cases / active cases * 100)
covid_data['daily_growth_rate'] = (covid_data['new_cases'] / covid_data['active']) * 100

# Example: Calculate cases per 100k population (assuming population data is available)
# If no population data, skip this or add hypothetical values
covid_data['cases_per_100k'] = (covid_data['confirmed'] / 100000)

# Example: Mortality ratio
covid_data['mortality_ratio'] = (covid_data['deaths'] / covid_data['confirmed']) * 100

# Check the dataset after feature engineering
covid_data.head()

import matplotlib.pyplot as plt
import seaborn as sns

# Correlation heatmap with only numeric columns
numeric_data = covid_data.select_dtypes(include=['float64', 'int64'])  # Select numeric columns
plt.figure(figsize=(10, 8))
sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', fmt=".2f")  # Generate heatmap
plt.title('Correlation Heatmap')
plt.show()

target_column = 'deaths'
X = numeric_data.drop([target_column], axis=1)
y = numeric_data[target_column]

from sklearn.model_selection import train_test_split

# Splitting features and labels
X = covid_data.drop('deaths', axis=1)
y = covid_data['deaths']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Identify numeric columns
numeric_columns = X_train.select_dtypes(include=['number']).columns
categorical_columns = X_train.select_dtypes(exclude=['number']).columns

# Apply threshold check only on numeric columns
X_train[numeric_columns] = X_train[numeric_columns].applymap(
    lambda x: np.nan if pd.notnull(x) and abs(x) > threshold else x
)
X_test[numeric_columns] = X_test[numeric_columns].applymap(
    lambda x: np.nan if pd.notnull(x) and abs(x) > threshold else x
)

# Example: Fill missing values for categorical columns
X_train[categorical_columns] = X_train[categorical_columns].fillna('Unknown')
X_test[categorical_columns] = X_test[categorical_columns].fillna('Unknown')

# Confirm there are no NaN, inf, or extreme values
print(X_train.isnull().sum())
print(np.isfinite(X_train[numeric_columns]).all())

from sklearn.preprocessing import OneHotEncoder

# Encode categorical data
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_columns]))
X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_columns]))

# Assign the correct column names to the encoded data
X_train_encoded.columns = encoder.get_feature_names_out(categorical_columns)
X_test_encoded.columns = encoder.get_feature_names_out(categorical_columns)

# Reset indices for concatenation
X_train_encoded.reset_index(drop=True, inplace=True)
X_test_encoded.reset_index(drop=True, inplace=True)

# Recombine numeric and encoded data
X_train = pd.concat([X_train[numeric_columns].reset_index(drop=True), X_train_encoded], axis=1)
X_test = pd.concat([X_test[numeric_columns].reset_index(drop=True), X_test_encoded], axis=1)

from sklearn.preprocessing import StandardScaler

# Scale the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# encoded data (X_train_encoded and X_test_encoded)
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X_train_encoded, y_train)  # Ensure this step executes without error

# make predictions
y_pred = model.predict(X_test_encoded)

# Evaluate the model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")

# Importing the necessary metrics for evaluation
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Predictions on the test data
y_pred = model.predict(X_test_encoded)

# Evaluate the model
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")

# Classification report for precision, recall, and f1-score for each class
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")

# Confusion matrix to see the breakdown of predictions
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")

# Re-adding the original categorical columns back to the encoded data (optional)
X_train_encoded_with_originals = pd.concat([X_train[numeric_columns].reset_index(drop=True),
                                            X_train_encoded], axis=1)

X_test_encoded_with_originals = pd.concat([X_test[numeric_columns].reset_index(drop=True),
                                           X_test_encoded], axis=1)

# Save the new dataframe that includes both encoded and original data
X_train_encoded_with_originals.to_csv('X_train_with_originals.csv', index=False)
X_test_encoded_with_originals.to_csv('X_test_with_originals.csv', index=False)

# Save the model
import joblib

joblib.dump(model, 'trained_model.pkl')

# Save the DataFrame as a CSV file
X_train_encoded.to_csv('X_train_encoded.csv', index=False)
X_test_encoded.to_csv('X_test_encoded.csv', index=False)